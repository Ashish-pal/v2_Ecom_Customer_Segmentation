# -*- coding: utf-8 -*-
"""v2Ecom_Customer_Segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10zMe9gRo5vEmL3qhygrWQL9FfGqWeXxl
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
from google.colab import files

uploaded = files.upload()

dataset = pd.read_excel("ecom_customer_data.xlsx")

dataset.head()

dataset.shape

dataset.info()

dataset.describe()

dataset.isna().sum()

dataset.dtypes

dataset.columns

obj = (dataset.dtypes == 'object')
object_cols = list(obj[obj].index)
print("Categorical variables:",len(object_cols))

int_ = (dataset.dtypes == 'int')
num_cols = list(int_[int_].index)
print("Integer variables:",len(num_cols))

fl = (dataset.dtypes == 'float')
fl_cols = list(fl[fl].index)
print("Float variables:",len(fl_cols))

"""###EDA"""

dataset['Gender'] = dataset['Gender'].fillna(dataset['Gender'].mode()[0])

dataset.isna().sum()

dataset.Gender.value_counts()

"""###Visualization"""

sns.countplot(data=dataset,x='Gender')
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(dataset['Orders'], kde=True, bins=20)
plt.title('Distribution of Orders')
plt.xlabel('Orders')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(data=dataset,x='Orders',hue='Gender')
plt.suptitle("Overall Orders VS Gender wise Orders")
plt.show()

#Orders and searches of each brands
cols=list(dataset.columns[2:])
def dist_list(lst):
  plt.figure(figsize=(30,30))
  for i, col in enumerate(lst,1):
    plt.subplot(6,6,i)
    sns.boxplot(data=dataset,x=dataset[col])
dist_list(cols)

plt.figure(figsize=(20,15))
sns.heatmap(dataset.iloc[:,3:].corr(), annot=False, cmap='coolwarm')
plt.show()

dataset.iloc[:2,:].hist(figsize=(40,30))
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import silhouette_score
from sklearn.cluster import KMeans
from yellowbrick.cluster import KElbowVisualizer

new_df=dataset.copy()
new_df['Total Search']=new_df.iloc[:,3:].sum(axis=1)

new_df.sort_values('Total Search', ascending=False)

plt.figure(figsize=(13,8))
plt_data=new_df.sort_values('Total Search',ascending=False)[['Cust_ID','Gender','Total Search']].head(10)
sns.barplot(data=plt_data,
            x='Cust_ID',
            y='Total Search',
            hue='Gender',
            order=plt_data.sort_values('Total Search',ascending=False).Cust_ID)
plt.title("Top 10 Cust_ID based on Total Searches")
plt.show()

"""###Scaling"""

x=dataset.iloc[:,2:].values
x

scale=MinMaxScaler()
features=scale.fit_transform(x)
features

"""###Elbow Method to get optimal number of K values"""

inertia=[] #initialization and store the values computed for different number of clusters
for i in range(1,16):
  k_means=KMeans(n_clusters=i)
  k_means=k_means.fit(features)
  inertia.append(k_means.inertia_)

#Elbow graph
plt.figure(figsize=(20,7))
plt.subplot(1,2,1)
plt.plot(range(1,16),inertia, 'bo-')
plt.xlabel('No of clusters'),plt.ylabel('Inertia')

plt.subplot(1,2,2)
kmeans=KMeans()
visualize=KElbowVisualizer(kmeans,k=(1,16))
visualize.fit(features)
plt.suptitle("Elbow Graph and Elbow Visualizer")
visualize.poof()
plt.show()

"""###Silhouette Score of Each Value of K"""

silhouette_avg=[]
for i in range(2,16):
  #initialize kmeans cluster
  kmeans=KMeans(n_clusters=i)
  cluster_labels=kmeans.fit_predict(features)
  silhouette_avg.append(silhouette_score(features,cluster_labels))

plt.figure(figsize=(10,7))
plt.plot(range(2,16),silhouette_avg,'bX-')
plt.xlabel('No of K')
plt.ylabel('Silhouette score')
plt.title('Silhouette analysis for optimal K')
plt.show()

"""###Kmeans Model with Value of 3"""

model=KMeans(n_clusters=3)
model=model.fit(features)

y_km=model.predict(features)
centers=model.cluster_centers_

dataset['Cluster']=pd.DataFrame(y_km)
dataset.to_csv("Cluster_data", index=False)

dataset["Cluster"].value_counts()

sns.countplot(data=dataset,x='Cluster')
plt.show()

cluster_dataset=pd.read_csv('Cluster_data')
cluster_dataset.head()

cluster_dataset['Total Search']=cluster_dataset.iloc[:,3:38].sum(axis=1)

"""###Analyze Cluster 0"""

cl_0=cluster_dataset.groupby(['Cluster','Gender'], as_index=False).sum().query('Cluster==0')
cl_0

plt.figure(figsize=(15,6))
plt.subplot(1,2,1)
sns.countplot(data=cluster_dataset.query('Cluster==0'),x='Gender')
plt.title('Customers count')

plt.subplot(1,2,2)
sns.barplot(data=cl_0,x='Gender',y='Total Search')
plt.title('Total Searches by Gender')
plt.suptitle('No. of customer and their total searches in "Cluster 0"')
plt.show()

"""###Analyze Cluster 1"""

cl_1=cluster_dataset.groupby(['Cluster','Gender'], as_index=False).sum().query('Cluster==1')
cl_1

plt.figure(figsize=(15,6))
plt.subplot(1,2,1)
sns.countplot(data=cluster_dataset.query('Cluster==1'),x='Gender')
plt.title('Customers count')

plt.subplot(1,2,2)
sns.barplot(data=cl_1,x='Gender',y='Total Search')
plt.title('Total Searches by Gender')
plt.suptitle('No. of customer and their total searches in "Cluster 0"')
plt.show()

"""###Analyze Cluster 2"""

cl_2=cluster_dataset.groupby(['Cluster','Gender'], as_index=False).sum().query('Cluster==2')
cl_2

plt.figure(figsize=(15,6))
plt.subplot(1,2,1)
sns.countplot(data=cluster_dataset.query('Cluster==2'),x='Gender')
plt.title('Customers count')

plt.subplot(1,2,2)
sns.barplot(data=cl_2,x='Gender',y='Total Search')
plt.title('Total Searches by Gender')
plt.suptitle('No. of customer and their total searches in "Cluster 0"')
plt.show()

"""###Overall Cluster Analysis"""

final_df=cluster_dataset.groupby(['Cluster'],as_index=False).sum()
final_df

plt.figure(figsize=(10,7))
sns.countplot(data=cluster_dataset,x='Cluster',hue='Gender')
plt.title('Total Customer on each cluster')
plt.show()

plt.figure(figsize=(10,6))
plt.subplot(1,2,1)
sns.barplot(data=final_df,x='Cluster',y='Total Search')
plt.title('Total Searches by each group')

plt.subplot(1,2,2)
sns.barplot(data=final_df,x='Cluster',y='Orders')
plt.title('Past Orders by each group')
plt.suptitle('No. of times cluster searched the products and their past orders')
plt.show()

"""###Prediction Modeling and Evaluation on Overall Cluster Dataset"""

new_dataset = final_df
X = 'Cluster'
y = 'Total Search'

print("Features and Target:")
print(X)
print(y)

"""###KFold Cross Validation with Prediction for the Cluster Dataset as Clustered Overall Analysis"""

from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score

from sklearn.model_selection import KFold
def k_fold_validation(model, X, y, n_splits=5):
    # Convert pandas Series to numpy arrays for compatibility with KFold
    X = X.to_numpy().reshape(-1, 1)  # Reshape to 2D array as most sklearn models expect it
    y = y.to_numpy()

    kf = KFold(n_splits=n_splits, shuffle=True, random_state=0)
    r2_scores = []
    mse_scores = []

    for train_index, test_index in kf.split(X):
        # Access the data using the indices directly since X and y are already part of the DataFrame
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        r2_scores.append(r2_score(y_test, y_pred))
        mse_scores.append(mean_squared_error(y_test, y_pred))

    return np.mean(r2_scores), np.mean(mse_scores)


X = new_dataset['Cluster']
y = new_dataset['Total Search']

lr = LinearRegression()
lr_r2, lr_mse = k_fold_validation(lr, X, y, n_splits=3)
print(f"Linear Regression - Mean R2-Score: {lr_r2}")
print(f"Linear Regression - Mean MSE: {lr_mse} \n")


dt_regressor = DecisionTreeRegressor(random_state=0)
dt_r2, dt_mse = k_fold_validation(dt_regressor, X, y, n_splits=3)
print(f"Decision Tree Regression - Mean R2-Score: {dt_r2}")
print(f"Decision Tree Regression - Mean MSE: {dt_mse} \n")


rf_regressor = RandomForestRegressor(random_state=0)
rf_r2, rf_mse = k_fold_validation(rf_regressor, X, y, n_splits=3)
print(f"Random Forest Regression - Mean R2-Score: {rf_r2}")
print(f"Random Forest Regression - Mean MSE: {rf_mse} \n")


svm = SVR()
svm_r2, svm_mse = k_fold_validation(svm, X, y, n_splits=3)
print(f"SVM Regression - Mean R2-Score: {svm_r2}")
print(f"SVM Regression - Mean MSE: {svm_mse}")

"""###KFold Cross Validation with Prediction for the Overall Analysis"""

X = dataset[['Gender', 'Orders']]
y = dataset['Orders']

print("Features and Target:")
print(X)
print(y)

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
dataset['Gender'] = label_encoder.fit_transform(dataset['Gender'])

from sklearn.model_selection import KFold
def k_fold_validation(model, X, y, n_splits=5):
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=0)
    r2_scores = []
    mse_scores = []

    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        X_train = X_train.values.reshape(-1, 1)
        X_test = X_test.values.reshape(-1, 1)

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        r2_scores.append(r2_score(y_test, y_pred))
        mse_scores.append(mean_squared_error(y_test, y_pred))

    return np.mean(r2_scores), np.mean(mse_scores)


lr = LinearRegression()
lr_r2, lr_mse = k_fold_validation(lr, X, y, n_splits=5)
print(f"Linear Regression - Mean R2-Score: {lr_r2}")
print(f"Linear Regression - Mean MSE: {lr_mse} \n")


dt_regressor = DecisionTreeRegressor(random_state=0)
dt_r2, dt_mse = k_fold_validation(dt_regressor, X, y, n_splits=5)
print(f"Decision Tree Regression - Mean R2-Score: {dt_r2}")
print(f"Decision Tree Regression - Mean MSE: {dt_mse} \n")


rf_regressor = RandomForestRegressor(random_state=0)
rf_r2, rf_mse = k_fold_validation(rf_regressor, X, y, n_splits=5)
print(f"Random Forest Regression - Mean R2-Score: {rf_r2}")
print(f"Random Forest Regression - Mean MSE: {rf_mse} \n")


svm = SVR()
svm_r2, svm_mse = k_fold_validation(svm, X, y, n_splits=5)
print(f"SVM Regression - Mean R2-Score: {svm_r2}")
print(f"SVM Regression - Mean MSE: {svm_mse} \n")


kmeans_pca = KMeans()
kmeans_pca_r2, kmeans_pca_mse = k_fold_validation(kmeans_pca, X, y, n_splits=5)
print(f"Kmeans with PCA - Mean R2-Score: {svm_r2}")
print(f"Kmeans with PCA - Mean MSE: {svm_mse} \n")


kmeans_wpca = KMeans()
kmeans_wpca_r2, kmeans_wpca_mse = k_fold_validation(kmeans_wpca, X, y, n_splits=5)
print(f"Kmeans without PCA - Mean R2-Score: {svm_r2}")
print(f"Kmeans without PCA - Mean MSE: {svm_mse}")

